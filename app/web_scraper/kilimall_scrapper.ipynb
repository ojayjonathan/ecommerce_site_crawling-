{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from config import get_chrome_driver\n",
    "from utils import ProductSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KilimalSeleniumScrapper():\n",
    "    \"\"\"\n",
    "    search_parameters => dict object {q:query,page:page_number}\n",
    "    self.url = 'https://www.kilimall.co.ke/new/commoditysearch?'\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.items_found = 0\n",
    "        self.pages_found = 0\n",
    "        self.title = ''\n",
    "        self.driver = get_chrome_driver(incognito=True)\n",
    "        self.dataframe = pd.DataFrame(columns=[\"product_name\", \"item_link\",\"image_src\",\"price\",\"prev_price\", \"item_review\", \"rating\", 'per_discount'])\n",
    "    def call(self,filter_parameters,page_number='page_1'):\n",
    "        parameters='&'.join(['{}={}'.format(key,filter_parameters[key]) for key in filter_parameters.keys()])\n",
    "        print(self.url+parameters)\n",
    "        self.driver.get(self.url+parameters)\n",
    "        html_string = self.driver.page_source\n",
    "        soup= BeautifulSoup(html_string, 'lxml')\n",
    "        self.title = soup.title.text\n",
    "        ele_result= soup.body.find_all(class_=\"el-col el-col-6\") \n",
    "        for i, article in enumerate(ele_result):\n",
    "            item_link,prev_price, product_name, review, image_path,rating,price, per_discount =None, None, None, 0, None, None, None, '0%'\n",
    "            try:\n",
    "                price_ele = article.find(class_='wordwrap-price')\n",
    "                price = price_ele.find('span').text\n",
    "                prev_price =  price_ele.find(class_='twoksh').text\n",
    "                item_link = ('https://www.kilimall.co.ke/{}').format(article.a['href'])\n",
    "                product_name = article.find(class_='wordwrap').text\n",
    "                image_path=article.img['src']\n",
    "                per_discount = article.find(class_='greenbox').text\n",
    "                review = article.find(class_='sixtwo').text \n",
    "                if page_number=='page_1':\n",
    "                    self.result_found = soup.body.find(class_='results').text.split(' ')[1]\n",
    "                    pages_found = soup.body.find(class_='leftpaging').text.split('/')[-1]\n",
    "                    self.pages_found = int(pages_found)\n",
    "            except:\n",
    "                pass\n",
    "            if prev_price == None:\n",
    "                prev_price=price\n",
    "            item_data = ProductSerializer(name=product_name,item_link=item_link, \n",
    "                                          image_path=image_path, price=price, \n",
    "                                          prev_price=prev_price, item_reviews=review,rating=rating, per_discount=per_discount)\n",
    "            page_dataframe = pd.DataFrame(item_data,index=[0])        \n",
    "            self.dataframe = pd.concat([self.dataframe,page_dataframe], ignore_index=True)\n",
    "    def get_result(self, filter_parameters, max_number_pages=5):\n",
    "        self.call(filter_parameters)\n",
    "        for i in range(2,max_number_pages+1):\n",
    "            if i<=self.pages_found:\n",
    "                filter_parameters['page']=i\n",
    "                self.call(filter_parameters,page_number='page_{}'.format(i))\n",
    "        self.driver.quit()        \n",
    "        return {'title':self.title,'items_found':self.result_found,'dataframe':self.dataframe}          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ojay/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: use options instead of chrome_options\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.kilimall.co.ke/new/commoditysearch?q=men+watches\n",
      "https://www.kilimall.co.ke/new/commoditysearch?q=men+watches&page=2\n",
      "https://www.kilimall.co.ke/new/commoditysearch?q=men+watches&page=3\n"
     ]
    }
   ],
   "source": [
    "kilimal = KilimalSeleniumScrapper()\n",
    "result = kilimal.get_result({'q':'men+watches'},max_number_pages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_chrome_driver??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
